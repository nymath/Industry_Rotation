{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建仓库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git init;\\\n",
    "# git add .;\\\\\n",
    "# git commit -m 'Initial commit'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建虚拟环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m venv venv;\\\n",
    "# source ./venv/bin/activate;\\\n",
    "# deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OLS in module statsmodels.regression.linear_model:\n",
      "\n",
      "class OLS(WLS)\n",
      " |  OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |  \n",
      " |  Ordinary Least Squares\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  **kwargs\n",
      " |      Extra arguments that are used to set model properties when using the\n",
      " |      formula interface.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights : scalar\n",
      " |      Has an attribute weights = array(1.0) due to inheritance from WLS.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  WLS : Fit a linear model using Weighted Least Squares.\n",
      " |  GLS : Fit a linear model using Generalized Least Squares.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  No constant is added by the model unless you are using formulas.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>> import numpy as np\n",
      " |  >>> duncan_prestige = sm.datasets.get_rdataset(\"Duncan\", \"carData\")\n",
      " |  >>> Y = duncan_prestige.data['income']\n",
      " |  >>> X = duncan_prestige.data['education']\n",
      " |  >>> X = sm.add_constant(X)\n",
      " |  >>> model = sm.OLS(Y,X)\n",
      " |  >>> results = model.fit()\n",
      " |  >>> results.params\n",
      " |  const        10.603498\n",
      " |  education     0.594859\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  >>> results.tvalues\n",
      " |  const        2.039813\n",
      " |  education    6.892802\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  >>> print(results.t_test([1, 0]))\n",
      " |                               Test for Constraints\n",
      " |  ==============================================================================\n",
      " |                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |  ------------------------------------------------------------------------------\n",
      " |  c0            10.6035      5.198      2.040      0.048       0.120      21.087\n",
      " |  ==============================================================================\n",
      " |  \n",
      " |  >>> print(results.f_test(np.identity(2)))\n",
      " |  <F test: F=array([[159.63031026]]), p=1.2607168903696672e-20, df_denom=43, df_num=2>\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OLS\n",
      " |      WLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str\n",
      " |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      " |      alpha : scalar or array_like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt : scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array_like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      statsmodels.base.elastic_net.RegularizedResults\n",
      " |          The regularized results.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The elastic net uses a combination of L1 and L2 penalties.\n",
      " |      The implementation closely follows the glmnet package in R.\n",
      " |      \n",
      " |      The function that is minimized is:\n",
      " |      \n",
      " |      .. math::\n",
      " |      \n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |      \n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |      \n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |      \n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |      \n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |      \n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The square root lasso approach is a variation of the Lasso\n",
      " |      that is largely self-tuning (the optimal tuning parameter\n",
      " |      does not depend on the standard deviation of the regression\n",
      " |      errors).  If the errors are Gaussian, the tuning parameter\n",
      " |      can be taken to be\n",
      " |      \n",
      " |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      " |      \n",
      " |      where n is the sample size and p is the number of predictors.\n",
      " |      \n",
      " |      The square root lasso uses the following keyword arguments:\n",
      " |      \n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The cvxopt module is required to estimate model using the square root\n",
      " |      lasso.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |         generalized linear models via coordinate descent.  Journal of\n",
      " |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |      \n",
      " |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      " |         pivotal recovery of sparse signals via conic programming.\n",
      " |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      " |  \n",
      " |  hessian(self, params, scale=None)\n",
      " |      Evaluate the Hessian function at a given point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter vector at which the Hessian is computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The Hessian matrix.\n",
      " |  \n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Calculate the weights for the Hessian.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameter at which Hessian is evaluated.\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      " |  \n",
      " |  loglike(self, params, scale=None)\n",
      " |      The likelihood function for the OLS model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The coefficients with which to estimate the log-likelihood.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The likelihood function evaluated at params.\n",
      " |  \n",
      " |  score(self, params, scale=None)\n",
      " |      Evaluate the score function at a given point.\n",
      " |      \n",
      " |      The score corresponds to the profile (concentrated)\n",
      " |      log-likelihood in which the scale parameter has been profiled\n",
      " |      out.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter vector at which the score function is\n",
      " |          computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The score vector.\n",
      " |  \n",
      " |  whiten(self, x)\n",
      " |      OLS model whitener does nothing.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          Data to be whitened.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          The input array unmodified.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      OLS : Fit a linear model using Ordinary Least Squares.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |  \n",
      " |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |      Full fit of the model.\n",
      " |      \n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators.\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance\n",
      " |          estimators.\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      RegressionResults\n",
      " |          The model estimation results.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      RegressionResults\n",
      " |          The results container.\n",
      " |      RegressionResults.get_robustcov_results\n",
      " |          A method to change the covariance estimator used when fitting the\n",
      " |          model.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |  \n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Construct a random number generator for the predictive distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array_like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize model components.\n",
      " |  \n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Parameters of a linear model.\n",
      " |      exog : array_like, optional\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          An array of fitted values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |  \n",
      " |  df_model\n",
      " |      The model degree of freedom.\n",
      " |      \n",
      " |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      " |      constant is included.\n",
      " |  \n",
      " |  df_resid\n",
      " |      The residual degree of freedom.\n",
      " |      \n",
      " |      The dof is defined as the number of observations minus the rank of\n",
      " |      the regressor matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |      \n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = ['a','b','c','d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.remove('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'c', 'd']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079e87f824df5e6b38a7b88e40dc2ff705d3b55588765c4fa4284c46fb940b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
